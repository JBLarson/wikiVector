â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         WIKIPEDIA EMBEDDINGS TESTING SUITE - QUICK REFERENCE        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“¦ WHAT YOU GOT
â”œâ”€ 5 Testing Tools (40+ tests, benchmarks, quality analysis)
â”œâ”€ Interactive Explorer (real-time queries)
â”œâ”€ Dashboard Generator (beautiful HTML reports)
â””â”€ Complete Documentation

ğŸš€ QUICK START
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Start server:      python server.py                             â”‚
â”‚ 2. Run tests:         ./quickstart.sh                              â”‚
â”‚ 3. Choose option 5    (runs everything in ~10 min)                 â”‚
â”‚ 4. View dashboard:    open wiki_dashboard.html                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ› ï¸ INDIVIDUAL TOOLS

  test_wiki_api.py      â†’  Comprehensive API testing (~2 min)
  â”œâ”€ 40+ test queries across 10+ categories
  â”œâ”€ Natural language, exact matches, edge cases
  â””â”€ Output: wiki_test_results.json

  benchmark_wiki.py     â†’  Performance & stress testing (~3 min)
  â”œâ”€ Sequential vs concurrent loads
  â”œâ”€ Latency analysis (P50, P95, P99)
  â””â”€ Output: benchmark_results.json

  analyze_quality.py    â†’  Semantic quality analysis (~5 min)
  â”œâ”€ Domain clustering (70-90% connectivity!)
  â”œâ”€ Relationship detection (IS-A, PART-OF)
  â”œâ”€ Multi-hop reasoning, analogies
  â””â”€ Output: semantic_quality_report.json

  explore_wiki.py       â†’  Interactive exploration
  â”œâ”€ Commands: query, compare, explore, analyze
  â”œâ”€ Real-time semantic neighborhood traversal
  â””â”€ No output file (interactive)

  generate_dashboard.py â†’  Visual HTML dashboard (<1 min)
  â”œâ”€ Combines all test results
  â”œâ”€ Charts, metrics, progress bars
  â””â”€ Output: wiki_dashboard.html

ğŸ“Š EXAMPLE OUTPUTS

Test Suite:
  âœ“ Tests passed: 38/40 (95.0%)
  âœ“ Average recall: 0.847
  âœ“ Average latency: 156ms

Performance:
  âœ“ Throughput: 21.4 queries/sec
  âœ“ P95 latency: 178ms
  âœ“ Success rate: 100%

Quality:
  âœ“ Programming Languages: 78.5% clustering
  âœ“ Renaissance Artists: 91.2% clustering
  âœ“ Disambiguation: Working perfectly

ğŸ¯ UNDERSTANDING RESULTS

Latency Guide:
  < 100ms  = Excellent â­â­â­
  100-200ms = Good â­â­
  200-500ms = Moderate â­
  > 500ms  = Needs tuning âš ï¸

Recall Guide:
  > 0.8   = Excellent â­â­â­
  0.6-0.8 = Good â­â­
  0.4-0.6 = Moderate â­
  < 0.4   = Needs work âš ï¸

Score Ranges (0-100):
  90-100 = Highly related
  70-90  = Strongly related
  50-70  = Moderately related
  < 50   = Weakly related

ğŸ”§ COMMON TASKS

Run everything once:
  $ ./quickstart.sh
  > Choose option 5

Test single query:
  $ python explore_wiki.py "your query here"

Quick quality check:
  $ python test_wiki_api.py

Performance check:
  $ python benchmark_wiki.py

View results:
  $ open wiki_dashboard.html

ğŸ› TROUBLESHOOTING

Server not running?
  â†’ python server.py

Slow queries (>500ms)?
  â†’ Edit server.py: ivf_index.nprobe = 8  # Lower for speed

Low recall?
  â†’ Edit server.py: WEIGHT_SEMANTIC = 0.85  # Higher for quality

Inconsistent results?
  â†’ Check: normalize_embeddings=True in model.encode()

ğŸ“ FILES GENERATED

After running all tests:
  â”œâ”€ wiki_test_results.json          (test details)
  â”œâ”€ benchmark_results.json          (performance)
  â”œâ”€ semantic_quality_report.json    (quality metrics)
  â””â”€ wiki_dashboard.html             (visual report)

ğŸ“š DOCUMENTATION

  COMPLETE_GUIDE.md      â†’ Full guide with examples
  README_TESTING.md      â†’ Detailed tool documentation
  QUICK_REFERENCE.txt    â†’ This file!

ğŸ“ NEXT STEPS

After first run:
  1. Review dashboard â†’ Get overview
  2. Check latencies â†’ Tune if needed
  3. Test your domain â†’ Add custom tests
  4. Iterate â†’ Adjust, re-test, compare

ğŸ’¡ TIPS

â€¢ Run option 5 first for complete baseline
â€¢ Use interactive explorer to understand behavior
â€¢ Add domain-specific tests for your use case
â€¢ Compare before/after when tuning parameters
â€¢ Dashboard updates automatically from JSON files

ğŸ‰ YOUR SYSTEM STATS

Articles: ~7M Wikipedia articles
Index: IVF+PQ optimized FAISS
Model: all-MiniLM-L6-v2 (384 dim)
Scoring: 70% semantic + 30% popularity
Expected: 100-200ms latency, >0.7 recall

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  START: ./quickstart.sh â†’ Option 5 â†’ Coffee â˜• â†’ View Dashboard    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
